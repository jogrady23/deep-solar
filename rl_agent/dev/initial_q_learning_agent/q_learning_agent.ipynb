{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f938c4bc-21e7-4c41-91ba-1298c6e6ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import random\n",
    "random.seed(1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aec774-5b99-4ae4-b2bf-4a254cf187c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial_interface as si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748f703-5499-4dcb-8843-f213e728d516",
   "metadata": {},
   "source": [
    "### Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b46c3b-db28-4915-ae4d-97ad707df240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(data_path):\n",
    "    raw_df = pd.read_csv(data_path)\n",
    "    data_df = raw_df.copy()\n",
    "    # Make current positive\n",
    "    data_df = data_df.drop_duplicates(subset=['motor_1_position','motor_2_position'])\n",
    "    data_df['I_ivp_1'] = data_df['I_ivp_1'].abs()\n",
    "    data_df['power'] = data_df['I_ivp_1'] * data_df['V_ivp_1']\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "949a872e-633f-4d7f-a911-8fa0ab392a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_motor_positions_to_index(position_tuple):\n",
    "    # position tuple is (m1 position, m2 position)\n",
    "    return (int(position_tuple[0]//5), int(position_tuple[1]//5))\n",
    "\n",
    "def convert_index_to_motor_positions(index_tuple):\n",
    "    return (index_tuple[0]*5, index_tuple[1]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c1839ace-528a-400e-a5c7-cbc2cc4d16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_max_array_index_loop(array):\n",
    "    # Finds the argmax and randomly selects if multiple\n",
    "    array_max = -10000\n",
    "    max_list = []\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            if array[i][j] > array_max:\n",
    "                array_max = array[i][j]\n",
    "                max_list = [[i,j]]\n",
    "            elif array[i][j] == array_max:\n",
    "                max_list.append([i,j])\n",
    "    if len(max_list) > 1:\n",
    "        max_index = random.choice(max_list)\n",
    "    else:\n",
    "        max_index = max_list[0]\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "709aea08-d088-43c9-91cb-7f5183d45be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_max_array_index(array):\n",
    "    max_indeces = np.where(array == array.max())\n",
    "    index_pairs = [(max_indeces[0][x], max_indeces[1][x]) for x in range(len(max_indeces[0]))]\n",
    "    return random.choice(index_pairs)\n",
    "\n",
    "def random_array_index(array):\n",
    "    x_index = range(array.shape[0])\n",
    "    y_index = range(array.shape[1])\n",
    "    return (random.choice(x_index), random.choice(y_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d769522c-bc81-4f81-9618-d8337978124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolarEnv:\n",
    "    def __init__(self, reward_data_path, shape=(37,37)):\n",
    "        self.shape = shape\n",
    "        self.reward_array = np.zeros(shape)\n",
    "        # load in reward data\n",
    "        rewards = load_and_prep_data(reward_data_path)\n",
    "        for index, row in rewards.iterrows():\n",
    "            motor_1_index = int(row['motor_1_position'].item()//5)\n",
    "            motor_2_index = int(row['motor_2_position'].item()//5)\n",
    "            position_reward = row['power'].item()\n",
    "            self.reward_array[motor_1_index][motor_2_index] = position_reward\n",
    "    \n",
    "    # For debugging\n",
    "    def get_reward_array(self):\n",
    "        return self.reward_array\n",
    "    \n",
    "    def get_env_shape(self):\n",
    "        return self.reward_array.shape\n",
    "                                          \n",
    "    # Not needed right now\n",
    "    def env_init(self):\n",
    "        \"\"\"\n",
    "        Setup for the environment called when the experiment first starts.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    # Not needed right now\n",
    "    def env_start(self):\n",
    "        \"\"\"\n",
    "        The first method called when the experiment starts, called before the\n",
    "        agent starts.\n",
    "\n",
    "        Returns:\n",
    "            The first state from the environment.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def env_step(self, action):\n",
    "        \"\"\"A step taken by the environment.\n",
    "\n",
    "        Args:\n",
    "            action: The action taken by the agent, a tuple of motor positions\n",
    "\n",
    "        Returns:\n",
    "            (float, state): a tuple of the reward, state\n",
    "        \"\"\"\n",
    "        index_tuples = convert_motor_positions_to_index(action)\n",
    "        return self.reward_array[index_tuples[0]][index_tuples[1]], convert_index_to_motor_positions(index_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac738823-8ec9-4565-b25a-cca2f587288d",
   "metadata": {},
   "source": [
    "Visualizing the reward array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec059f9e-08a3-4211-8617-0a2285fc9384",
   "metadata": {},
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680ef40-22fa-445b-ad71-31b7c2a07567",
   "metadata": {},
   "source": [
    "Agent will start out as a TD(0) agent with epsilon-greedy policy\n",
    "* V(st) = V(st) + step_size * [Rewardt+1 + discount_factor * V(st+1) - V(st)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a469e872-b860-43ca-858f-6c185cb07c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolarAgent:\n",
    "    def __init__(self, step_size, epsilon, discount_factor, initialization_value, env):\n",
    "        self.step_size = step_size\n",
    "        self.epsilon = epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "        self.env_shape = env.get_env_shape()\n",
    "        self.state_values = np.full(self.env_shape, initialization_value)\n",
    "        self.last_state = None\n",
    "        self.state = None\n",
    "        self.last_reward = None\n",
    "        self.reward = None\n",
    "        self.env = env\n",
    "        self.total_energy = 0\n",
    "        self.transition_dict = None\n",
    "    \n",
    "    def get_state_value_array(self):\n",
    "        return self.state_values.copy()\n",
    "    \n",
    "    def agent_policy(self):\n",
    "        # if random greedy\n",
    "        if random.random() <= self.epsilon:\n",
    "            action = random_array_index(self.state_values)\n",
    "        # otherwise arg max\n",
    "        else:\n",
    "            action = arg_max_array_index(self.state_values)\n",
    "        return convert_index_to_motor_positions(action)\n",
    "    \n",
    "    def agent_start(self):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (Numpy array): the state from the\n",
    "                environment's evn_start function.\n",
    "        Returns:\n",
    "            self.last_action [int] : The first action the agent takes.\n",
    "        \"\"\"\n",
    "        self.last_state = [90,90]\n",
    "        self.last_reward = 0\n",
    "        self.state, self.reward = self.env.env_step(self.last_state)\n",
    "    \n",
    "    def get_state_values(self, state):\n",
    "        converted_index = convert_motor_positions_to_index(state)\n",
    "        return self.state_values[converted_index[0]][converted_index[1]]\n",
    "    \n",
    "    def agent_step(self):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward [float]: the reward received for taking the last action taken\n",
    "            state [int]: the state from the environment's step, where the agent ended up after the last step\n",
    "        Returns:\n",
    "            self.last_action [int] : The action the agent is taking.\n",
    "        \"\"\"\n",
    "        # Make a policy decision\n",
    "        action = self.agent_policy()\n",
    "        \n",
    "        # Interact with the environment\n",
    "        reward, next_state = self.env.env_step(action)\n",
    "        \n",
    "        # TD Update\n",
    "        new_state_value = self.get_state_values(next_state)\n",
    "        last_state_value = self.get_state_values(self.last_state)\n",
    "        error_term = reward + self.discount_factor * new_state_value - last_state_value\n",
    "        last_state_index = convert_motor_positions_to_index(self.last_state)\n",
    "        self.state_values[last_state_index[0]][last_state_index[1]] = last_state_value + self.step_size * error_term\n",
    "        \n",
    "        # For debugging\n",
    "        self.transition_dict = {\n",
    "            'reward': reward,\n",
    "            'new_state_value': new_state_value,\n",
    "            'last_state_value': last_state_value,\n",
    "            'error_term': error_term,\n",
    "            'updated_value_estimate': last_state_value + self.step_size * error_term\n",
    "        }\n",
    "        \n",
    "        # Update internal variables\n",
    "        self.last_state = next_state\n",
    "        \n",
    "        # For tracking\n",
    "        self.total_energy += reward\n",
    "    \n",
    "    def get_agent_energy(self):\n",
    "        return self.total_energy\n",
    "    \n",
    "    def get_transition_dict(self):\n",
    "        return self.transition_dict\n",
    "    \n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12058c-3e32-4115-8995-86d652e0eee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "68aa2bd1-a495-4e6b-bab5-b3603828961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../rl_agent/simulation_data/data/corrected_motors/run_5_kitchen_no_lights.csv'\n",
    "env = SolarEnv(reward_data_path=data_path, shape=(37,37))\n",
    "agent = SolarAgent(step_size=0.5, epsilon=0.01, discount_factor=0.1, initialization_value=1.0, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "00ac6ae9-c969-4b78-ab49-f84cb97e8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.agent_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb780377-0c7f-4d20-a411-201b7f7fd06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.04 s, sys: 55 ms, total: 8.09 s\n",
      "Wall time: 8.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 8000):\n",
    "    agent.agent_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de4c3e09-203a-4e0d-9cee-fc2524cfee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 ms, sys: 4.28 ms, total: 560 ms\n",
      "Wall time: 562 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 8000):\n",
    "    agent.agent_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b186b-15a3-49c8-b4f8-7488e6a28b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(agent.get_state_value_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3c14a-3ba8-48bc-a2a1-4a1683f901b6",
   "metadata": {},
   "source": [
    "### Environment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947c87e-4f34-4997-8959-9d341491fc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.imshow(env.get_reward_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46258b2-b13c-41dd-9e5a-5ca28d90076c",
   "metadata": {},
   "source": [
    "### Resume here with experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a67299-2264-4a6e-bab9-1fc64e0da7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data_path = '../../../rl_agent/simulation_data/data/corrected_motors/run_5_kitchen_no_lights.csv'\n",
    "experiment_env = SolarEnv(reward_data_path=experiment_data_path, shape=(37,37))\n",
    "experiment_agent = SolarAgent(step_size=0.3, epsilon=0.05, discount_factor=0, initialization_value=0.5, env=experiment_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c783450-4b65-463b-8bd4-8dc519388fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = 100000\n",
    "interval = 100\n",
    "progress_dict = {}\n",
    "experiment_agent.agent_start()\n",
    "progress_dict['0'] = {\n",
    "            'state_value': experiment_agent.get_state_value_array(),\n",
    "            'total_power': experiment_agent.get_agent_energy()\n",
    "        }\n",
    "for i in tqdm(range(1, steps + 1)):\n",
    "    experiment_agent.agent_step()\n",
    "    if i%interval == 0:\n",
    "        progress_dict[str(i)] = {\n",
    "            'state_value': experiment_agent.get_state_value_array(),\n",
    "            'total_power': experiment_agent.get_agent_energy()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6281d3-e51c-426a-bc3a-ed1b86865347",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(progress_dict['10000']['state_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31204ffc-8057-4a8b-b578-ac821124fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99a6fb-8a62-441a-a0ca-fec33d5f4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_list = [progress_dict[x]['state_value'] for x in progress_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69babe20-9b1a-4630-960c-b8cf3bd37128",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=[go.Heatmap(z=matrix_list[0])],\n",
    "    layout=go.Layout(\n",
    "        title=\"Frame 0\",\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[dict(label=\"Play\",\n",
    "                          method=\"animate\",\n",
    "                          args=[None]),\n",
    "                    dict(label=\"Pause\",\n",
    "                         method=\"animate\",\n",
    "                         args=[None,\n",
    "                               {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                \"mode\": \"immediate\",\n",
    "                                \"transition\": {\"duration\": 0}}],\n",
    "                         )])]\n",
    "    ),\n",
    "    frames=[go.Frame(data=[go.Heatmap(z=matrix_list[i])], \n",
    "                     layout=go.Layout(title_text=f\"Frame {i * interval}\")) for i in range(1, len(matrix_list))]\n",
    ")\n",
    "\n",
    "fig.update_layout({\n",
    "    'height': 600,\n",
    "    'width': 600}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72827c36-139e-4032-8eab-65d772cb6d04",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff4000-d540-4893-a785-11236d03159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request codes\n",
    "MOTOR_CONTROL = 1000\n",
    "STATE_REQUEST = 2000\n",
    "RESET_CODE = 6666\n",
    "\n",
    "def scan_space(arduino):\n",
    "    # Run start\n",
    "    run_start = time.time()\n",
    "    data_dict_list = []\n",
    "    last_motor_interval = 0\n",
    "    last_measure_interval = -1\n",
    "    motor_frequency = 2\n",
    "    measure_frequency = 1\n",
    "    # Set timeouts\n",
    "    abort = False\n",
    "    \n",
    "    for xy_degree in range(0, 181, 5):\n",
    "        for yz_degree in range(0, 181, 5):\n",
    "            si.write_serial_line(arduino, [MOTOR_CONTROL, xy_degree, yz_degree], print_message=False)\n",
    "            new_message, abort = si.listen_for_serial(arduino)\n",
    "            if new_message is not None and not abort:\n",
    "                data_dict_list.append(new_message)\n",
    "            elif abort:\n",
    "                break\n",
    "            else:\n",
    "                print('Empty message received without abort issue')\n",
    "            time.sleep(0.1) # Wait for steady state\n",
    "        if abort:\n",
    "            break\n",
    "        print('xy:',xy_degree,'yz:',yz_degree)\n",
    "    # Write back to start state\n",
    "    write_serial_line(arduino, [si.MOTOR_CONTROL, 90, 90])\n",
    "\n",
    "    return pd.DataFrame(data_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07994661-9e43-4372-b543-b2641c5cad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('\\nARDUINO CONTROL TESTING')\n",
    "    print('-------------------------')\n",
    "    # Initialize serial port\n",
    "    print('\\nIniitalizing device...')\n",
    "    serial_port = '/dev/cu.usbmodem14101'\n",
    "    baud_rate = 9600\n",
    "    timeout = 5\n",
    "    arduino = si.initialize_serial(serial_port=serial_port, baud_rate=baud_rate, timeout=timeout)\n",
    "    print('\\t - SUCCESS: Device initialized.')\n",
    "    \n",
    "    si.write_serial_line(arduino, [MOTOR_CONTROL, 90, 90])\n",
    "\n",
    "    # Run a loop where motor position incremented every 5 seconds, print out message\n",
    "    print('\\nBeginning loop sequence...')\n",
    "#     data = scan_space(arduino)\n",
    "    print('\\t - Loop complete.')\n",
    "\n",
    "    # Add relative time to returned data and print out\n",
    "#     data['t_relative'] = data['timestamp'] - data['timestamp'].iloc[0]\n",
    "    print('\\nData broadcasted by Arduino:\\n')\n",
    "    \n",
    "#     data.to_csv('/Users/jackogrady/Git/rl-solar/rl_agent/simulation_data/data/run_6_kitchen_no_lights_swapped_motors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55694cd-2430-4233-943d-51758fc16cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1b648-e1a8-4d7d-84ca-56d3c3b878eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_serial_line(arduino, [1000, 180, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e08c6-02c9-4216-80d9-4968f08b292b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
